% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/unified_pipeline.R
\name{run_unified_pipeline}
\alias{run_unified_pipeline}
\title{Run the complete PH pipeline}
\usage{
run_unified_pipeline(
  metadata_path,
  results_dir = "results",
  num_cores = 8,
  integration_methods = "seurat",
  run_cluster = FALSE,
  run_betti = FALSE,
  run_cross_iteration = FALSE,
  custom_iteration_inputs = NULL,
  ...
)
}
\arguments{
\item{metadata_path}{Path to a CSV file containing dataset metadata.}

\item{results_dir}{Directory where results should be written.}

\item{num_cores}{Number of cores to use for parallel tasks.}

\item{integration_methods}{Character vector of integration methods to apply
when processing datasets. Use "seurat" to produce the Seurat integration
iteration, "harmony" to produce the Harmony iteration, or supply both to run
them side by side (raw and SCT iterations are always generated alongside the
chosen integration outputs).}

\item{run_cluster}{If `TRUE`, run clustering comparisons during
post-processing.}

\item{run_betti}{If `TRUE`, compute and compare Betti curves.}

\item{run_cross_iteration}{If `TRUE`, perform cross-iteration analyses.}

\item{custom_iteration_inputs}{Optional named list mapping iteration labels or
prefixes to lists with `seurat_object_path`, `ph_list_path`, `bdm_matrix_path`,
`sdm_matrix_path`, `landscape_list_path`, and
`landscape_l2_distance_matrix_path` entries, or a path to an R script that
defines such a list. When provided, matching iterations load the supplied
objects before recomputing only the missing matrices and clustering outputs. If
`NULL`, the function looks for a populated template at
`inst/extdata/custom_iteration_inputs_template.R` and will import it
automatically when valid paths are detected.}

\item{...}{Additional arguments passed to the underlying processing
functions.}
}
\value{
The list produced by `process_datasets_PH()` that contains the
  processed iterations and metadata column names.
}
\description{
This wrapper function first processes the datasets using
`process_datasets_PH()` and then optionally performs the
post-processing analyses provided by `run_postprocessing_pipeline()`.
}
\examples{
\dontrun{
metadata <- read.csv("./data/metadata.csv")
run_unified_pipeline(metadata_path = "./data/metadata.csv")
}
}
