% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/unified_pipeline.R
\name{run_unified_pipeline}
\alias{run_unified_pipeline}
\title{Run the complete PH pipeline}
\usage{
run_unified_pipeline(
  metadata_path,
  results_dir = "results",
  num_cores = 8,
  integration_method = "seurat",
  run_cluster = FALSE,
  run_betti = FALSE,
  run_cross_iteration = FALSE,
  ...
)
}
\arguments{
\item{metadata_path}{Path to a CSV file containing dataset metadata.}

\item{results_dir}{Directory where results should be written.}

\item{num_cores}{Number of cores to use for parallel tasks.}

\item{integration_method}{Integration method to apply when processing
datasets. Options include "seurat", "liger" or "mnn".}

\item{run_cluster}{If `TRUE`, run clustering comparisons during
post-processing.}

\item{run_betti}{If `TRUE`, compute and compare Betti curves.}

\item{run_cross_iteration}{If `TRUE`, perform cross-iteration analyses.}

\item{...}{Additional arguments passed to the underlying processing
functions.}
}
\value{
The list produced by `process_datasets_PH()` that contains the
  processed iterations and metadata column names.
}
\description{
This wrapper function first processes the datasets using
`process_datasets_PH()` and then optionally performs the
post-processing analyses provided by `run_postprocessing_pipeline()`.
}
\examples{
\dontrun{
metadata <- read.csv("./data/metadata.csv")
run_unified_pipeline(metadata_path = "./data/metadata.csv")
}
}
